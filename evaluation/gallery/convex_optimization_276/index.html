<!doctype html>
<meta charset="utf-8">
<link rel="stylesheet" href="../../static/style.css">
<title>Convex Optimization page 276 — I❤️LA</title>
<body>
  <header>
    <link href="../../static/prism.css" rel="stylesheet" />
    <h1> Convex Optimization page 276 </h1>
  </header>
  <script src="../../static/prism.js"></script>
  <div class="page">
    
  

  
    <div class="gallery_post">

    <!-- <p>Implementing equations from Convex Optimization page 276.</p>
 -->

    
     <p>An example from <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Convex Optimization page 276</a>
    
    
    
    <p>The original equation:
      <p><img src=../../static/gallery_res/Convex%20Optimization%20page%20276/convex_optimization_276.png alt="placeholder" width="700" style='object-fit: scale-down;'>
    

    
      <p>I❤️LA implementation:
      <div class="code_block" style='height: auto;'><pre ><code class="language-cpsp">given
A_i ∈ ℝ^(m_i × n)  
b_i ∈ ℝ^m_i 
`x₀` ∈ ℝ^n  

min_(x ∈ ℝ^n) ∑_i ‖A_i x + b_i‖ + (1/2)‖x-`x₀`‖²</code></pre></div>
    

    

     
    
      <p>I❤️LA compiled to Python/NumPy/SciPy:
      <div class="code_block"><pre ><code class="language-python">&#34;&#34;&#34;
given
A_i ∈ ℝ^(m_i × n)  
b_i ∈ ℝ^m_i 
`x₀` ∈ ℝ^n  

min_(x ∈ ℝ^n) ∑_i ‖A_i x + b_i‖ + (1/2)‖x-`x₀`‖²
&#34;&#34;&#34;
import numpy as np
import scipy
import scipy.linalg
from scipy import sparse
from scipy.integrate import quad
from scipy.optimize import minimize


class convex_optimization_276ResultType:
    def __init__( self, ret):
        self.ret = ret


def convex_optimization_276(A, b, x0):
    A = np.asarray(A)
    b = np.asarray(b)
    x0 = np.asarray(x0, dtype=np.float64)

    dim_0 = A.shape[0]
    n = A[0].shape[1]
    assert x0.shape == (n,)

    def target_0(x):
        sum_0 = 0
        for i in range(1, len(b)+1):
            sum_0 += np.linalg.norm(A[i-1] @ x + b[i-1], 2)
        return sum_0 + (1 / 2) * np.power(np.linalg.norm(x - x0, 2), 2)
    ret = minimize(target_0, np.zeros(n)).fun
    return convex_optimization_276ResultType(ret)


def generateRandomData():
    dim_0 = np.random.randint(10)
    n = np.random.randint(10)
    b = []
    A = []
    for i in range(dim_0):
        m_0 = np.random.randint(10)
        b.append(np.random.randn(m_0))
        A.append(np.random.randn(m_0, n))
    x0 = np.random.randn(n)
    return A, b, x0


if __name__ == &#39;__main__&#39;:
    A, b, x0 = generateRandomData()
    print(&#34;A:&#34;, A)
    print(&#34;b:&#34;, b)
    print(&#34;x0:&#34;, x0)
    func_value = convex_optimization_276(A, b, x0)
    print(&#34;return value: &#34;, func_value.ret)</code></pre></div>
    

    
      <p>I❤️LA compiled to MATLAB:
      <div class="code_block"><pre ><code class="language-matlab">function output = convex_optimization_276(A, b, x0)
% output = convex_optimization_276(A, b, `x₀`)
%
%    given
%    A_i ∈ ℝ^(m_i × n)  
%    b_i ∈ ℝ^m_i 
%    `x₀` ∈ ℝ^n  
%    
%    min_(x ∈ ℝ^n) ∑_i ‖A_i x + b_i‖ + (1/2)‖x-`x₀`‖²
    if nargin==0
        warning(&#39;generating random input data&#39;);
        [A, b, x0] = generateRandomData();
    end
    function [A, b, x0] = generateRandomData()
        dim_0 = randi(10);
        n = randi(10);
        b = {};
        A = {};
        for i = 1:dim_0
            m_2 = randi(10);
            b = [b; randn(m_2)];
            A = [A; randn(m_2, n)];
        end
        x0 = randn(n,1);
    end

    x0 = reshape(x0,[],1);

    dim_0 = size(A, 1);
    n = size(A{1}, 2);
    assert( numel(x0) == n );

    function ret = target_1(x)
        sum_0 = 0;
        for i = 1:size(b, 1)
            sum_0 = sum_0 + norm(A{i} * x + b{i}, 2);
        end
        ret = sum_0 + (1 / 2) * norm(x - x0, 2).^2;
    end
    [~,optimize_0] = fminunc(@target_1,zeros(n,1));
    ret = optimize_0;
    output.ret = ret;
end
</code></pre></div>
    

    
      <p>I❤️LA compiled to LaTeX:
      <div class="code_block"><pre ><code class="language-tex">\documentclass[12pt]{article}
\usepackage{mathdots}
\usepackage[bb=boondox]{mathalfa}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{libertine}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage[paperheight=8in,paperwidth=4in,margin=.3in,heightrounded]{geometry}
\let\originalleft\left
\let\originalright\right
\renewcommand{\left}{\mathopen{}\mathclose\bgroup\originalleft}
\renewcommand{\right}{\aftergroup\egroup\originalright}
\begin{document}

\begin{center}
\resizebox{\textwidth}{!} 
{
\begin{minipage}[c]{\textwidth}
\begin{align*}
\intertext{given} 
\mathit{A}_{\mathit{i}} &amp; \in \mathbb{R}^{ \mathit{m}_{\mathit{i}} \times \mathit{n} } \\
\mathit{b}_{\mathit{i}} &amp; \in \mathbb{R}^{ \mathit{m}_{\mathit{i}}} \\
\textit{x₀} &amp; \in \mathbb{R}^{ \mathit{n}} \\
\\
 \omit \span \begin{aligned} \min_{\mathit{x} \in \mathbb{R}^{ \mathit{n}}} \quad &amp; \sum_\mathit{i} \left\|\mathit{A}_{ \mathit{i} }\mathit{x} + \mathit{b}_{ \mathit{i} }\right\|_2 + \left( \frac{1}{2} \right)\left\|\mathit{x} - \textit{x₀}\right\|_2^{2} \\
\end{aligned} \\
\end{align*}
\end{minipage}
}
\end{center}

\end{document}
</code></pre></div>
    

    

      <p>I❤️LA LaTeX output:
      <div>
      <iframe src=../../static/gallery_res/Convex%20Optimization%20page%20276/convex_optimization_276.pdf frameborder="0" width="700" height="1000"><br>
      </div>
    
    </div>
  


 



  </div>
</body>
